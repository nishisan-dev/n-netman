# n-netman â€” Nishi Network Manager

[![Go Version](https://img.shields.io/badge/go-1.23+-blue.svg)](https://golang.org/)
[![License](https://img.shields.io/badge/license-Nishi--NC-orange.svg)](LICENSE)

**n-netman** Ã© um agente leve para criaÃ§Ã£o e gerenciamento de **overlays VXLAN L3/L2** entre hosts Linux rodando KVM/libvirt.

## ğŸ¯ Objetivo

Permitir que redes virtuais distribuÃ­das sejam criadas de forma **declarativa e simples**, eliminando a necessidade de soluÃ§Ãµes complexas como OVS.

### O que jÃ¡ funciona

- âœ… CriaÃ§Ã£o/atualizaÃ§Ã£o de interfaces VXLAN e bridges Linux
- âœ… SincronizaÃ§Ã£o de FDB para peers configurados (flooding BUM)
- âœ… BUM em head-end-replication (FDB) e multicast (grupo IP)
- âœ… **Troca de rotas via gRPC** (ExchangeState, AnnounceRoutes, WithdrawRoutes)
- âœ… InstalaÃ§Ã£o automÃ¡tica de rotas recebidas no kernel
- âœ… CLI `nnet` com `apply`, `status`, `routes`, `doctor`, `version`
- âœ… Carregamento/validaÃ§Ã£o de config YAML com defaults
- âœ… Healthchecks HTTP e endpoint de mÃ©tricas
- âœ… **Status real dos peers** via endpoint `/status` (healthy/unhealthy/disconnected)
- âœ… **EstatÃ­sticas de rotas** (exported, installed, per-peer)
- âœ… **Cleanup automÃ¡tico** de rotas no shutdown e quando peers caem (`flush_on_peer_down`)
- âœ… **Multi-Overlay (v2)** â€” MÃºltiplos VXLANs com configuraÃ§Ã£o de routing por overlay
- âœ… Bridge com IPv4/IPv6 por overlay (para nexthop e anÃºncios)

### Em progresso

- âš ï¸ TLS para comunicaÃ§Ã£o gRPC entre peers
- âš ï¸ IntegraÃ§Ã£o libvirt/attach de VMs
- âš ï¸ Netplan parsing e rotas conectadas/estÃ¡ticas

---

## ğŸ“‹ PrÃ©-requisitos

### Sistema Operacional
- Linux com kernel 3.7+ (suporte a VXLAN)
- Testado em Ubuntu 22.04+, Debian 12+

### DependÃªncias
```bash
# Verificar suporte a VXLAN e bridges
lsmod | grep vxlan
lsmod | grep bridge

# Se nÃ£o estiverem carregados:
sudo modprobe vxlan
sudo modprobe bridge
```

### Build
- Go 1.23 ou superior

```bash
# Verificar versÃ£o do Go
go version
```

---

## ğŸš€ InstalaÃ§Ã£o

### OpÃ§Ã£o 1: Build do Fonte

```bash
# Clonar repositÃ³rio
git clone https://github.com/nishisan-dev/n-netman.git
cd n-netman

# Build
make build

# Ou manualmente:
go build -o bin/nnetd ./cmd/nnetd
go build -o bin/nnet ./cmd/nnet
```

### OpÃ§Ã£o 2: InstalaÃ§Ã£o no Sistema

```bash
# Build e instalar em $GOPATH/bin
make install

# Ou copiar manualmente
sudo cp bin/nnetd /usr/local/bin/
sudo cp bin/nnet /usr/local/bin/
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### Criar DiretÃ³rio de ConfiguraÃ§Ã£o

```bash
sudo mkdir -p /etc/n-netman
```

### Arquivo de ConfiguraÃ§Ã£o

Crie o arquivo `/etc/n-netman/n-netman.yaml`:

```yaml
version: 1

node:
  id: "host-a-01"          # Identificador Ãºnico deste nÃ³
  hostname: "host-a"
  tags:
    - "datacenter-1"
    - "kvm"

# IntegraÃ§Ã£o com netplan (somente leitura)
netplan:
  enabled: true
  underlay:
    prefer_interfaces:
      - "eth0"
      - "ens3"
    prefer_address_families:
      - "ipv4"

# IntegraÃ§Ã£o com KVM/libvirt (opcional)
kvm:
  enabled: false           # Defina como true se usar libvirt
  bridges:
    - name: "br-nnet-100"
      stp: false
      mtu: 1450
      manage: true

# ConfiguraÃ§Ã£o do overlay VXLAN
overlay:
  vxlan:
    vni: 100               # VXLAN Network Identifier
    name: "vxlan100"
    dstport: 4789
    mtu: 1450
    learning: true
    bridge: "br-nnet-100"

  # Peers (outros hosts no overlay)
  peers:
    - id: "host-b-01"
      endpoint:
        address: "10.10.0.12"    # IP underlay do peer
      auth:
        mode: "psk"
        psk_ref: "file:/etc/n-netman/psk/host-b-01.key"
      health:
        keepalive_interval_ms: 1500
        dead_after_ms: 6000

    - id: "host-c-01"
      endpoint:
        address: "10.10.0.13"

# Roteamento entre peers
routing:
  enabled: true
  export:
    export_all: false
    networks:
      - "172.16.10.0/24"   # Redes que este nÃ³ anuncia
      - "2001:db8:10::/64" # Suporte IPv6
    include_connected: true
    include_netplan_static: true
    metric: 100
  import:
    accept_all: false
    allow:
      - "172.16.0.0/16"
      - "2001:db8::/32"
    deny:
      - "0.0.0.0/0"        # Bloquear default route
    install:
      table: 100           # Tabela de roteamento customizada
      replace_existing: true
      flush_on_peer_down: true
      route_lease_seconds: 30

# Topologia
topology:
  mode: "direct-preferred"
  transit: "deny"          # NÃ£o permitir trÃ¢nsito por padrÃ£o

# SeguranÃ§a do control-plane
security:
  control_plane:
    transport: "grpc"
    listen:
      address: "0.0.0.0"
      port: 9898
    tls:
      enabled: false
      cert_file: "/etc/n-netman/tls/server.crt"
      key_file: "/etc/n-netman/tls/server.key"
      ca_file: "/etc/n-netman/tls/ca.crt"

# Observabilidade
observability:
  logging:
    level: "info"
    format: "json"
  metrics:
    enabled: true
    listen:
      address: "127.0.0.1"
      port: 9109
  healthcheck:
    enabled: true
    listen:
      address: "127.0.0.1"
      port: 9110
```

### Chaves PSK (Opcional)

Se usar autenticaÃ§Ã£o PSK entre peers:

```bash
sudo mkdir -p /etc/n-netman/psk

# Gerar chave para cada peer
openssl rand -hex 32 | sudo tee /etc/n-netman/psk/host-b-01.key
sudo chmod 600 /etc/n-netman/psk/*.key
```

### Multi-Overlay (Config v2) ğŸ†•

A partir da versÃ£o 2 do config, vocÃª pode definir mÃºltiplos overlays VXLAN, cada um com seu prÃ³prio routing:

```yaml
version: 2

node:
  id: "host-a"
  hostname: "host-a"

overlays:
  # Production Overlay (VNI 100)
  - vni: 100
    name: "vxlan-prod"
    dstport: 4789
    mtu: 1450
    learning: true
    bridge:
      name: "br-prod"
      ipv4: "10.100.0.1/24"
    underlay_interface: "ens3"    # Interface fÃ­sica para este overlay
    bum:
      mode: "head-end-replication"
    routing:
      export:
        networks:
          - "172.16.10.0/24"
        metric: 100
      import:
        accept_all: true
        install:
          table: 100

  # Management Overlay (VNI 200)
  - vni: 200
    name: "vxlan-mgmt"
    dstport: 4789
    mtu: 1450
    learning: true
    bridge:
      name: "br-mgmt"
      ipv4: "10.200.1.1/24"
    underlay_interface: "ens4"
    bum:
      mode: "multicast"
      group: "239.1.1.200"
    routing:
      export:
        networks:
          - "10.200.0.0/24"
        metric: 200
      import:
        accept_all: true
        install:
          table: 200

# Peers (shared across overlays)
overlay:
  peers:
    - id: "host-b"
      endpoint:
        address: "192.168.56.12"
```

Veja o exemplo completo em [`examples/multi-overlay.yaml`](examples/multi-overlay.yaml).

---

## ğŸ® Uso

### CLI - Comandos DisponÃ­veis

```bash
# Ver ajuda
nnet --help

# Ver versÃ£o
nnet version

# Verificar configuraÃ§Ã£o e mostrar status
nnet -c /etc/n-netman/n-netman.yaml status

# Visualizar rotas configuradas
nnet -c /etc/n-netman/n-netman.yaml routes

# Dry-run (mostra o que seria feito sem executar)
nnet -c /etc/n-netman/n-netman.yaml apply --dry-run

# Aplicar configuraÃ§Ã£o (requer root)
sudo nnet -c /etc/n-netman/n-netman.yaml apply

# DiagnÃ³stico do sistema
nnet -c /etc/n-netman/n-netman.yaml doctor
```

### Exemplo de SaÃ­da: `nnet status`

```
ğŸ–¥ï¸  Node: host-a (host-a)

ğŸ“¡ VXLAN Interfaces:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸŸ¢ UP vxlan100 (VNI 100, MTU 1450)

ğŸŒ‰ Bridges:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸŸ¢ UP br-nnet-100 (MTU 1450)
      Attached: [vxlan100]

ğŸ‘¥ Configured Peers:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ID      ENDPOINT       STATUS               ROUTES
  â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€
  host-b  192.168.56.12  ğŸŸ¢ healthy (5s ago)   1
  host-c  192.168.56.13  ğŸŸ¢ healthy (3s ago)   1

ğŸ“Š Route Statistics:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸ“¤ Exported:   1 route(s) (172.16.10.0/24)
  ğŸ“¥ Installed:  2 route(s) in table 100
      â€¢ 172.16.20.0/24 via 192.168.56.12 (host-b)
      â€¢ 172.16.30.0/24 via 192.168.56.13 (host-c)
```

### Daemon

```bash
# Iniciar daemon em foreground (requer root)
sudo nnetd -config /etc/n-netman/n-netman.yaml

# Ver versÃ£o
nnetd -version
```

### Systemd Service (Opcional)

Crie `/etc/systemd/system/n-netman.service`:

```ini
[Unit]
Description=n-netman VXLAN Overlay Manager
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
ExecStart=/usr/local/bin/nnetd -config /etc/n-netman/n-netman.yaml
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl daemon-reload
sudo systemctl enable n-netman
sudo systemctl start n-netman
sudo systemctl status n-netman
```

---

## ğŸ§ª Lab Testing (Vagrant)

O projeto inclui um `Vagrantfile` para testar multi-overlay em um ambiente com 3 VMs.

### Topologia do Lab (Multi-Overlay)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Underlay Networks                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Production: 192.168.56.0/24    â”‚    Management: 192.168.57.0/24           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     host-a        â”‚       host-b        â”‚        host-c                       â”‚
â”‚  Prod: .56.11     â”‚    Prod: .56.12     â”‚     Prod: .56.13                    â”‚
â”‚  Mgmt: .57.11     â”‚    Mgmt: .57.12     â”‚     Mgmt: .57.13                    â”‚
â”‚                   â”‚                     â”‚                                     â”‚
â”‚ VNI 100 (Prod):   â”‚ VNI 100 (Prod):     â”‚ VNI 100 (Prod):                     â”‚
â”‚ 172.16.10.0/24    â”‚ 172.16.20.0/24      â”‚ 172.16.30.0/24                      â”‚
â”‚                   â”‚                     â”‚                                     â”‚
â”‚ VNI 200 (Mgmt):   â”‚ VNI 200 (Mgmt):     â”‚ VNI 200 (Mgmt):                     â”‚
â”‚ 10.200.10.0/24    â”‚ 10.200.20.0/24      â”‚ 10.200.30.0/24                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Requisitos

- [Vagrant](https://www.vagrantup.com/) instalado
- [VirtualBox](https://www.virtualbox.org/) instalado
- ~2GB de RAM livre

### Subir o Lab

```bash
# Subir as 3 VMs (primeira vez demora ~5min)
vagrant up

# Ver status
vagrant status
```

### Testar a Troca de Rotas

```bash
# Terminal 1: host-a
vagrant ssh host-a
sudo nnetd -config /etc/n-netman/n-netman.yaml

# Terminal 2: host-b
vagrant ssh host-b
sudo nnetd -config /etc/n-netman/n-netman.yaml

# Terminal 3: host-c
vagrant ssh host-c
sudo nnetd -config /etc/n-netman/n-netman.yaml
```

Aguarde ~5 segundos e verifique as rotas aprendidas:

```bash
# Em qualquer VM
ip route show table 100

# SaÃ­da esperada (ex: em host-a):
# 172.16.20.0/24 via <next-hop> dev br-nnet-100 proto 99
# 172.16.30.0/24 via <next-hop> dev br-nnet-100 proto 99
```

### Script de ValidaÃ§Ã£o

```bash
# Em cada VM, rodar o script de teste
./n-netman/scripts/lab-test.sh
```

### Comandos Ãšteis

```bash
# Destruir VMs
vagrant destroy -f

# Recriar uma VM especÃ­fica
vagrant destroy host-a -f && vagrant up host-a

# SSH em uma VM
vagrant ssh host-b
```

---

## ğŸ“Š Observabilidade

### MÃ©tricas Prometheus

DisponÃ­veis em `http://127.0.0.1:9109/metrics`. Nota: mÃ©tricas registradas, mas a atualizaÃ§Ã£o ainda nÃ£o estÃ¡ implementada (exceto `peers_configured`).

| MÃ©trica | DescriÃ§Ã£o |
|---------|-----------|
| `nnetman_reconciliations_total` | Total de ciclos de reconciliaÃ§Ã£o |
| `nnetman_reconciliation_errors_total` | Erros de reconciliaÃ§Ã£o |
| `nnetman_reconciliation_duration_seconds` | DuraÃ§Ã£o dos ciclos de reconciliaÃ§Ã£o |
| `nnetman_last_reconcile_timestamp_seconds` | Timestamp do Ãºltimo reconcile |
| `nnetman_vxlans_active` | Interfaces VXLAN ativas |
| `nnetman_bridges_active` | Bridges ativas |
| `nnetman_fdb_entries_total` | Total de entradas FDB |
| `nnetman_peers_configured` | Peers configurados |
| `nnetman_peers_connected` | Peers conectados |
| `nnetman_peers_healthy` | Peers saudÃ¡veis |
| `nnetman_routes_exported` | Rotas exportadas |
| `nnetman_routes_imported` | Rotas importadas |
| `nnetman_grpc_requests_total` | Total de requisiÃ§Ãµes gRPC |
| `nnetman_grpc_request_duration_seconds` | DuraÃ§Ã£o das requisiÃ§Ãµes gRPC |

### Health Checks

```bash
# Liveness
curl http://127.0.0.1:9110/livez

# Readiness
curl http://127.0.0.1:9110/readyz

# Health geral
curl http://127.0.0.1:9110/healthz

# Status detalhado (peers + rotas)
curl http://127.0.0.1:9110/status
```

---

## ğŸ§© Componentes Internos (Go)

- `cmd/nnetd`: daemon (carrega config, inicia observabilidade e reconciler)
- `cmd/nnet`: CLI para aplicar config e inspecionar estado
- `internal/config`: structs, defaults e validaÃ§Ã£o do YAML
- `internal/reconciler`: loop que garante bridge/VXLAN/FDB conforme config
- `internal/netlink`: wrappers de bridge/VXLAN/FDB/rotas via netlink
- `internal/controlplane`: servidor/cliente gRPC com ExchangeState/Announce/Withdraw
- `internal/routing`: polÃ­ticas de export/import (helpers, ainda nÃ£o aplicados no daemon)
- `internal/observability`: mÃ©tricas Prometheus e healthchecks HTTP

---

## ğŸ”§ Troubleshooting

### Verificar Interfaces Criadas

```bash
# VXLAN
ip -d link show vxlan100

# Bridge
ip -d link show br-nnet-100
bridge link show

# FDB entries
bridge fdb show dev vxlan100
```

### Verificar Rotas

```bash
# Rotas na tabela 100
ip route show table 100

# Todas as rotas
ip route show
```

### Logs

```bash
# Com systemd
journalctl -u n-netman -f

# Em foreground
nnetd -config /etc/n-netman/n-netman.yaml 2>&1 | jq .
```

### DiagnÃ³stico Completo

```bash
nnet doctor
```

---

## ğŸ—ï¸ Arquitetura

### VisÃ£o Geral dos Componentes

O diagrama abaixo mostra a arquitetura atual. O control-plane agora implementa troca real de rotas via gRPC.

```plantuml
@startuml
skinparam componentStyle rectangle

package "n-netman daemon" {
    [Config Loader] --> [Reconciler]
    [Reconciler] --> [VXLAN Manager]
    [Reconciler] --> [Bridge Manager]
    [Reconciler] --> [FDB Manager]
    
    [gRPC Server] --> [Route Table]
    [gRPC Client] --> [Route Table]
    [Route Table] --> [Route Manager]
    
    [Observability] --> [Prometheus Metrics]
    [Observability] --> [Health Endpoints]
}

package "Linux Kernel" {
    [netlink API]
    [VXLAN Module]
    [Bridge Module]
    [Routing Tables]
}

[VXLAN Manager] --> [netlink API]
[Bridge Manager] --> [netlink API]
[FDB Manager] --> [netlink API]
[Route Manager] --> [Routing Tables]

cloud "Peer Nodes" {
    [Peer A gRPC]
    [Peer B gRPC]
}

[gRPC Client] --> [Peer A gRPC]
[gRPC Client] --> [Peer B gRPC]

@enduml
```

### Fluxo de ReconciliaÃ§Ã£o (Multi-Overlay)

```plantuml
@startuml
title Reconciler Loop (Multi-Overlay)

participant "Config" as C
participant "Reconciler" as R
participant "BridgeManager" as BM
participant "VXLANManager" as VM
participant "FDBManager" as FM
participant "Linux Kernel" as K

loop Every 10 seconds
    R -> C: GetOverlays()
    C --> R: []OverlayDef
    
    loop For each overlay (VNI 100, 200, ...)
        R -> BM: Ensure bridge exists (br-prod, br-mgmt)
        BM -> K: netlink: create/update bridge
        K --> BM: OK
        
        R -> VM: Ensure VXLAN exists (vxlan-prod, vxlan-mgmt)
        VM -> K: netlink: create/update vxlan
        K --> VM: OK
        
        VM -> BM: Attach VXLAN to bridge
        BM -> K: netlink: set master
        K --> BM: OK
        
        R -> FM: Sync FDB entries for overlay
        loop For each peer
            FM -> K: netlink: add FDB entry
            K --> FM: OK
        end
    end
    
    R -> R: Sleep 10s
end

@enduml
```

### Troca de Rotas entre Peers

```plantuml
@startuml
title Route Exchange Protocol

participant "Host A\n(curitiba-a-01)" as A
participant "Host B\n(curitiba-b-01)" as B
participant "Host C\n(curitiba-c-01)" as C

== Initial State Exchange ==
A -> B: ExchangeState(my_routes)
B --> A: StateResponse(peer_routes)

A -> C: ExchangeState(my_routes)
C --> A: StateResponse(peer_routes)

== Route Announcement ==
note over A: New local route detected:\n172.16.30.0/24

A -> B: AnnounceRoutes([172.16.30.0/24])
B --> A: RouteAck(accepted=true)
note over B: Install route:\nip route add 172.16.30.0/24\n  via <overlay-ip> table 100

A -> C: AnnounceRoutes([172.16.30.0/24])
C --> A: RouteAck(accepted=true)

== Keepalive ==
loop Every 1.5s
    A -> B: Keepalive(seq=N)
    B --> A: KeepaliveAck(seq=N)
end

== Route Withdrawal ==
note over A: Route removed locally

A -> B: WithdrawRoutes([172.16.30.0/24])
B --> A: RouteAck(processed=1)
note over B: Remove route from table 100

@enduml
```

### Topologia de Rede

```plantuml
@startuml
title VXLAN Overlay Network

cloud "Underlay Network\n(10.10.0.0/24)" {
    node "Host A\n10.10.0.11" as HA {
        rectangle "br-nnet-100" as BA
        rectangle "vxlan100" as VA
        rectangle "VM-A1" as VMA1
        rectangle "VM-A2" as VMA2
        
        VMA1 --> BA
        VMA2 --> BA
        VA --> BA
    }
    
    node "Host B\n10.10.0.12" as HB {
        rectangle "br-nnet-100" as BB
        rectangle "vxlan100" as VB
        rectangle "VM-B1" as VMB1
        
        VMB1 --> BB
        VB --> BB
    }
    
    node "Host C\n10.10.0.13" as HC {
        rectangle "br-nnet-100" as BC
        rectangle "vxlan100" as VC
        rectangle "VM-C1" as VMC1
        
        VMC1 --> BC
        VC --> BC
    }
}

VA <-[#blue,dashed]-> VB : VXLAN VNI 100\nUDP 4789
VA <-[#blue,dashed]-> VC : VXLAN VNI 100\nUDP 4789
VB <-[#blue,dashed]-> VC : VXLAN VNI 100\nUDP 4789

note bottom of HA
  Overlay: 172.16.10.0/24
end note

note bottom of HB
  Overlay: 172.16.20.0/24
end note

note bottom of HC
  Overlay: 172.16.30.0/24
end note

@enduml
```

---

## âš ï¸ LimitaÃ§Ãµes Atuais (MVP)

Esta Ã© uma versÃ£o MVP. As seguintes funcionalidades **ainda nÃ£o estÃ£o implementadas**:

### NÃ£o Funcional
| Item | Status | DescriÃ§Ã£o |
|------|--------|-----------|
| **TLS no gRPC** | âŒ | ComunicaÃ§Ã£o entre peers nÃ£o Ã© criptografada |
| **ValidaÃ§Ã£o de PSK** | âŒ | Chaves PSK sÃ£o lidas mas nÃ£o validadas |
| **IntegraÃ§Ã£o libvirt** | âŒ | Attach automÃ¡tico de VMs nÃ£o implementado |
| **Netplan parsing** | âŒ | Rotas do netplan nÃ£o sÃ£o lidas automaticamente |
| **PolÃ­ticas de import/export** | âŒ | `allow/deny/accept_all`, `export_all`, `include_connected`, `include_netplan_static` ainda nÃ£o sÃ£o aplicados no daemon |
| **Config TLS** | âŒ | `security.control_plane.tls` ainda nÃ£o Ã© usado |

### Parcialmente Funcional
| Item | Status | DescriÃ§Ã£o |
|------|--------|-----------|
| **VXLAN/Bridge** | âœ… | CriaÃ§Ã£o funciona (requer root) |
| **FDB entries** | âœ… | SincronizaÃ§Ã£o de peers funciona |
| **Troca de rotas gRPC** | âœ… | Handlers implementados, rotas instaladas |
| **Reconciler** | âœ… | Loop funciona |
| **MÃ©tricas** | âš ï¸ | Servidor inicia, mas mÃ©tricas nÃ£o sÃ£o atualizadas |
| **Healthcheck** | âœ… | Endpoints funcionam |
| **Status de peers** | âš ï¸ | Health check implementado, status pode demorar |
| **Multi-Overlay** | âš ï¸ | VXLAN/bridge por VNI ok, mas import table/lease ainda usa config global |

### PrÃ³ximas Prioridades
1. Adicionar TLS ao control plane
2. Testes de integraÃ§Ã£o com VMs reais em lab
3. ValidaÃ§Ã£o de PSK entre peers
4. IntegraÃ§Ã£o com libvirt para attach automÃ¡tico de VMs

---

## ğŸ“œ LicenÃ§a

Nishi Network Manager License (Non-Commercial Evaluation) - veja [LICENSE](LICENSE) para detalhes.

> **Nota:** Uso comercial requer licenÃ§a separada. Contate o Licensor para mais informaÃ§Ãµes.

---

## ğŸ¤ Contribuindo

1. Fork o repositÃ³rio
2. Crie uma branch (`git checkout -b feature/minha-feature`)
3. Commit suas mudanÃ§as (`git commit -am 'feat: adiciona minha feature'`)
4. Push para a branch (`git push origin feature/minha-feature`)
5. Abra um Pull Request
